from fastapi import APIRouter, HTTPException, Depends, Request
from fastapi.responses import StreamingResponse, Response
import asyncio
import json
import time
from typing import Any, Dict, AsyncGenerator, Optional
import os
from dotenv import load_dotenv
import logging
from collections import defaultdict
import re
# ç§»é™¤äº†urlparse importï¼Œä¸å†éœ€è¦ç›´æ¥è§£ææ•°æ®åº“URL

from sqlalchemy.orm import Session
from backend.app import schemas, utils
from database.connection import get_db

from langchain_google_genai import ChatGoogleGenerativeAI
# from langgraph.checkpoint.aiopg import PostgresSaver # Old import
from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver # CORRECTED Import for async Postgres
from langchain_core.messages import AIMessage, AIMessageChunk

from backend.sas.graph_builder import create_robot_flow_graph
from backend.config import DB_CONFIG # Import DB_CONFIG for database URL
from backend.app.dependencies import get_checkpointer
from backend.sas.state import RobotFlowAgentState # ç¡®ä¿å¯¼å…¥

load_dotenv() # Load .env file

logger = logging.getLogger(__name__)

# --- Stream End Sentinel ---
STREAM_END_SENTINEL = object()

# --- ç§»é™¤äº†ç›´æ¥æ•°æ®åº“è¿æ¥å‡½æ•°ï¼Œæ”¹ç”¨LangGraph API ---
# æ³¨æ„ï¼šä¸å†éœ€è¦ç›´æ¥æ“ä½œæ•°æ®åº“ï¼ŒLangGraphçš„checkpointerä¼šå¤„ç†æ‰€æœ‰æŒä¹…åŒ–æ“ä½œ

# --- LLM Initialization ---
LLM_INSTANCE = None
try:
    google_api_key = os.getenv("GOOGLE_API_KEY")
    gemini_model_name = os.getenv("GEMINI_MODEL", "gemini-2.5-flash-preview-05-20")
    if google_api_key:
        LLM_INSTANCE = ChatGoogleGenerativeAI(
            model=gemini_model_name,
            google_api_key=google_api_key,
            temperature=0,
            convert_system_message_to_human=True
        )
        logger.info(f"SAS Chat Router: Successfully initialized Gemini LLM: {gemini_model_name}")
    else:
        logger.error("SAS Chat Router: GOOGLE_API_KEY not found. LLM_INSTANCE is None.")
except Exception as e:
    logger.error(f"SAS Chat Router: Error initializing Gemini LLM: {e}. LLM_INSTANCE is None.")
# --- End LLM Initialization ---

# --- Persistence (Checkpointer) Initialization ---
# Note: AsyncPostgresSaver initialization needs to be done within an async context
# Since this module is loaded at startup, we'll need to initialize it lazily or use the app's checkpointer
CHECKPOINTER = None
print("SAS Chat Router: CHECKPOINTER will be initialized from app.state when needed.")
# --- End Persistence Initialization ---

# --- SAS App Initialization ---
# The sas_app will be created dynamically with the checkpointer from app.state
def get_sas_app(checkpointer: AsyncPostgresSaver = Depends(get_checkpointer)):
    """Get or create the SAS app with the current checkpointer"""
    if LLM_INSTANCE:
        return create_robot_flow_graph(llm=LLM_INSTANCE, checkpointer=checkpointer)
    else:
        logger.error("SAS Chat Router: LLM_INSTANCE is None, returning dummy app.")
        class DummySasApp:
            async def ainvoke(self, *args, **kwargs): return {"error": "LLM not configured for SAS app"}
            async def aget_state(self, *args, **kwargs): return {"error": "LLM not configured for SAS app"}
            async def aupdate_state(self, *args, **kwargs): return {"error": "LLM not configured for SAS app"}
            async def astream_events(self, *args, **kwargs):
                async def empty_generator():
                    yield {"error": "LLM not configured for SAS app"}
                    return
                return empty_generator()
        return DummySasApp()
# --- End SAS App Initialization ---

# --- æ–°å¢: æƒé™éªŒè¯ä¾èµ– ---
async def verify_flow_access(
    chat_id: str,
    db: Session = Depends(get_db),
    current_user: schemas.User = Depends(utils.get_current_user)
):
    """
    ä¸€ä¸ªä¾èµ–é¡¹ï¼Œç”¨äºéªŒè¯å½“å‰ç™»å½•ç”¨æˆ·æ˜¯å¦æœ‰æƒè®¿é—®æ­¤æµç¨‹(chat_id/flow_id)ã€‚
    å¦‚æœç”¨æˆ·æœªç™»å½•æˆ–æ— æƒè®¿é—®ï¼Œå°†å¼•å‘HTTPExceptionã€‚
    """
    utils.verify_flow_ownership(flow_id=chat_id, current_user=current_user, db=db)
    return current_user
# --- ç»“æŸæ–°å¢ ---

# --- æ–°å¢: ä¸“é—¨ç”¨äºflow_idå‚æ•°çš„æƒé™éªŒè¯ä¾èµ– ---
async def verify_flow_access_by_flow_id(
    flow_id: str,
    db: Session = Depends(get_db),
    current_user: schemas.User = Depends(utils.get_current_user)
):
    """
    ä¸€ä¸ªä¾èµ–é¡¹ï¼Œç”¨äºéªŒè¯å½“å‰ç™»å½•ç”¨æˆ·æ˜¯å¦æœ‰æƒè®¿é—®æ­¤æµç¨‹(é€šè¿‡flow_idå‚æ•°)ã€‚
    ä¸“é—¨ä¸ºä½¿ç”¨flow_idä½œä¸ºè·¯å¾„å‚æ•°çš„ç«¯ç‚¹è®¾è®¡ã€‚
    å¦‚æœç”¨æˆ·æœªç™»å½•æˆ–æ— æƒè®¿é—®ï¼Œå°†å¼•å‘HTTPExceptionã€‚
    """
    utils.verify_flow_ownership(flow_id=flow_id, current_user=current_user, db=db)
    return current_user
# --- ç»“æŸæ–°å¢ ---

router = APIRouter(
    prefix="/sas", # ä¿®å¤ï¼šç»Ÿä¸€ä½¿ç”¨ /sas å‰ç¼€ï¼Œä¸å‰ç«¯æœŸæœ›ä¿æŒä¸€è‡´
    tags=["sas"],
    responses={404: {"description": "Not found"}},
)

@router.post("/threads", status_code=201)  # è°ƒæ•´ä¸º /sas/threads
async def initialize_sas_thread(
    request: Request,
    sas_app = Depends(get_sas_app),
    user: schemas.User = Depends(utils.get_current_user),
    db: Session = Depends(get_db)
):
    """
    ä¸ºæ–°çš„ flow_id åˆå§‹åŒ– LangGraph çŠ¶æ€ã€‚
    å½“å‰ç«¯åˆ›å»ºä¸€ä¸ªæ–°æµç¨‹åï¼Œåº”ç«‹å³è°ƒç”¨æ­¤ç«¯ç‚¹ã€‚
    
    è¯·æ±‚ä½“åº”åŒ…å«: {"flow_id": "uuid-string"}
    """
    try:
        body = await request.json()
        flow_id = body.get("flow_id")
        
        if not flow_id:
            raise HTTPException(status_code=400, detail="Missing 'flow_id' in request body")
        
        # First, verify ownership of the flow record itself
        utils.verify_flow_ownership(flow_id, user, db)
        
        config = {"configurable": {"thread_id": flow_id}}
        
        # Check if state already exists to prevent accidental overwrites
        try:
            existing_state = await sas_app.aget_state(config)
            if existing_state and get_checkpoint_values(existing_state):
                logger.warning(f"SAS state for thread {flow_id} already exists. Not re-initializing.")
                return {"status": "exists", "thread_id": flow_id, "message": "SAS thread already initialized"}
        except Exception as check_error:
            logger.info(f"No existing state found for thread {flow_id}, proceeding with initialization")

        # Create a new, default state using dictionary to avoid type checking issues
        initial_state_dict = {
            "messages": [],
            "current_chat_id": flow_id,
            "thread_id": flow_id,
            "dialog_state": "initial",
            "config": {},
            "task_list_accepted": False,
            "module_steps_accepted": False,
            "is_error": False,
            "language": "zh",
            "relation_xml_content": "",
            "relation_xml_path": "",
            "revision_iteration": 0,
            "generated_node_xmls": [],
            "merged_xml_file_paths": []
        }
        
        await sas_app.aupdate_state(config, initial_state_dict)
        logger.info(f"Successfully initialized SAS state for thread_id: {flow_id}")
        
        return {"status": "created", "thread_id": flow_id, "message": "SAS thread initialized successfully"}

    except json.JSONDecodeError:
        raise HTTPException(status_code=400, detail="Invalid JSON in request body")
    except Exception as e:
        logger.error(f"Failed to initialize SAS state for thread_id {flow_id}: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Failed to initialize SAS state: {e}")

@router.delete("/threads/{thread_id}", status_code=204)  # è°ƒæ•´ä¸º /sas/threads/{thread_id}
async def delete_sas_thread(
    thread_id: str,
    sas_app = Depends(get_sas_app),
    user: schemas.User = Depends(verify_flow_access) # verify_flow_access uses chat_id, which is thread_id here
):
    """
    åˆ é™¤ä¸ flow_id å…³è”çš„ LangGraph çŠ¶æ€ã€‚
    æ³¨æ„ï¼šè¿™å–å†³äº checkpointer çš„å®ç°ã€‚
    å¯¹äº AsyncPostgresSaver, æ²¡æœ‰ç›´æ¥çš„åˆ é™¤æ–¹æ³•, æ­¤å¤„ä¸ºé€»è¾‘å ä½ã€‚
    """
    # verify_flow_access is already called via Depends
    logger.info(f"Attempting to delete SAS thread for flow {thread_id} by user {user.id}")
    
    # TODO: Implement actual deletion if the checkpointer backend supports it.
    # For now, this endpoint serves as a logical placeholder for the complete workflow.
    # e.g., await sas_app.checkpointer.adelete(config)
    
    try:
        # For now, we can try to clear the state by setting it to an empty/initial state
        # This is a workaround until proper deletion is implemented
        config = {"configurable": {"thread_id": thread_id}}
        
        # Try to get current state to verify it exists
        current_state = await sas_app.aget_state(config)
        if current_state and hasattr(current_state, 'values'):
            logger.info(f"Found existing SAS state for thread {thread_id}, clearing it")
            # Set to a minimal/empty state as a form of "deletion"
            empty_state_dict = {
                "messages": [],
                "current_chat_id": thread_id,
                "thread_id": thread_id,
                "dialog_state": "initial",
                "config": {},
                "task_list_accepted": False,
                "module_steps_accepted": False,
                "is_error": False,
                "language": "zh",
                "relation_xml_content": "",
                "relation_xml_path": "",
                "revision_iteration": 0,
                "generated_node_xmls": [],
                "merged_xml_file_paths": []
            }
            empty_state_dict['current_step_description'] = 'Thread deleted'
            
            await sas_app.aupdate_state(config, empty_state_dict)
            logger.info(f"Successfully cleared SAS state for thread {thread_id}")
        else:
            logger.info(f"No SAS state found for thread {thread_id}, nothing to delete")
            
    except Exception as e:
        logger.warning(f"Could not clear SAS state for thread {thread_id}: {e}")
        # Don't raise an exception here as the deletion might still be considered successful
        # from a business logic perspective
    
    logger.warning(f"SAS thread deletion for {thread_id} is not fully implemented in the backend checkpointer.")
    
    return Response(status_code=204)

# This function was a placeholder based on your last version of the file.
# If it was meant to interact with chat history from the DB for the graph,
# the graph itself (via checkpointer) would handle that state implicitly.
# Keeping it if it serves another purpose or if you want to adapt it.
async def get_chat_history(chat_id: str):
    # In a real scenario, this would fetch from a database or memory
    print(f"Fetching history for chat_id: {chat_id} (placeholder) - Note: Graph manages its own history via checkpointer.")
    return None # Or some history object

def get_checkpoint_values(checkpoint_obj) -> dict:
    """
    è·å–checkpointçš„valuesï¼ŒStateSnapshotå¯¹è±¡æœ‰.valueså±æ€§
    """
    if not checkpoint_obj:
        return {}
    
    try:
        # æ ¹æ®LangGraphæ–‡æ¡£ï¼ŒStateSnapshotå¯¹è±¡æœ‰.valueså±æ€§
        if hasattr(checkpoint_obj, 'values'):
            values = checkpoint_obj.values
            return values if isinstance(values, dict) else {}
        else:
            logger.warning(f"Checkpoint object missing .values attribute: {type(checkpoint_obj)}")
            return {}
    except Exception as e:
        logger.error(f"Error getting checkpoint values: {e}")
        return {}

async def _prepare_frontend_update(final_state: dict, flow_id: str) -> dict:
    """
    å‡†å¤‡å‰ç«¯æ›´æ–°æ•°æ®ï¼Œç›´æ¥ä»LangGraphçŠ¶æ€ï¼Œä¸å­˜å‚¨å‰¯æœ¬åˆ°Flowæ¨¡å‹
    éµå¾ªå•ä¸€æ•°æ®æºåŸåˆ™ï¼šLangGraph PostgreSQLæ˜¯å”¯ä¸€çœŸå®æ•°æ®æº
    """
    try:
        logger.info(f"[SAS Flow {flow_id}] ğŸ¯ å‡†å¤‡å‰ç«¯æ›´æ–°æ•°æ®...")
        
        # SAS specific important fields that should trigger frontend updates
        important_fields = [
            'sas_step1_generated_tasks',
            'sas_step2_generated_task_details', 
            'sas_step2_module_steps',
            'task_list_accepted',
            'module_steps_accepted',
            'dialog_state',
            'completion_status',
            'current_user_request',
            'revision_iteration',
            'clarification_question',
            'generated_node_xmls',
            'final_flow_xml_content'
        ]
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é‡è¦å­—æ®µå­˜åœ¨ï¼Œå†³å®šæ˜¯å¦éœ€è¦å‰ç«¯æ›´æ–°
        has_important_fields = any(field in final_state for field in important_fields)
        
        if has_important_fields:
            # æå–å‰ç«¯éœ€è¦çš„çŠ¶æ€æ•°æ®
            frontend_agent_state = {}
            update_types = []
            
            # ğŸ”§ ä¿®å¤ï¼šåºåˆ—åŒ– Pydantic æ¨¡å‹å¯¹è±¡ä»¥é¿å… JSON åºåˆ—åŒ–é”™è¯¯
            def serialize_pydantic_objects(obj):
                """å®‰å…¨åœ°åºåˆ—åŒ– Pydantic æ¨¡å‹å¯¹è±¡"""
                if hasattr(obj, 'model_dump'):
                    return obj.model_dump()
                elif hasattr(obj, 'dict'):
                    return obj.dict()
                elif isinstance(obj, list):
                    return [serialize_pydantic_objects(item) for item in obj]
                elif isinstance(obj, dict):
                    return {k: serialize_pydantic_objects(v) for k, v in obj.items()}
                else:
                    return obj
            
            for field in important_fields:
                if field in final_state:
                    # åºåˆ—åŒ–å¯èƒ½åŒ…å« Pydantic å¯¹è±¡çš„å­—æ®µ
                    field_value = final_state[field]
                    if field in ['sas_step1_generated_tasks', 'sas_step2_generated_task_details', 'sas_step2_module_steps']:
                        field_value = serialize_pydantic_objects(field_value)
                    
                    frontend_agent_state[field] = field_value
                    update_types.append(field)
                    
                    if field in ['dialog_state', 'sas_step1_generated_tasks', 'completion_status']:
                        logger.info(f"[SAS_FRONTEND_UPDATE] åŒ…å«é‡è¦å­—æ®µ: {field} = {field_value}")
            
            logger.info(f"[SAS Flow {flow_id}] ğŸ¯ å‡†å¤‡å‘é€å‰ç«¯æ›´æ–°ï¼Œå­—æ®µ: {update_types}")
            
            return {
                "needs_frontend_update": True,
                "update_types": update_types,
                "updated_agent_state": frontend_agent_state
            }
        else:
            logger.info(f"[SAS Flow {flow_id}] ğŸ¯ æ— é‡è¦å­—æ®µå˜åŒ–ï¼Œæ— éœ€å‰ç«¯æ›´æ–°")
            return {"needs_frontend_update": False}
            
    except Exception as e:
        logger.error(f"[SAS Flow {flow_id}] ğŸ¯ å‡†å¤‡å‰ç«¯æ›´æ–°å¤±è´¥: {e}", exc_info=True)
        return {"needs_frontend_update": False}

# Global event broadcasting system for SAS SSE events
class SASEventBroadcaster:
    def __init__(self):
        self.chat_queues: Dict[str, asyncio.Queue] = {}
        self.active_connections: Dict[str, int] = defaultdict(int)  # Track active SSE connections per chat
    
    async def get_or_create_queue(self, chat_id: str) -> asyncio.Queue:
        """Get or create event queue for a chat"""
        if chat_id not in self.chat_queues:
            self.chat_queues[chat_id] = asyncio.Queue(maxsize=1000)
        return self.chat_queues[chat_id]
    
    async def broadcast_event(self, chat_id: str, event_data: dict):
        """Broadcast event to all SSE connections for a chat"""
        if chat_id in self.chat_queues:
            try:
                await self.chat_queues[chat_id].put(event_data)
                logger.debug(f"[BROADCASTER] Event broadcast to chat {chat_id}: {event_data.get('type', 'unknown')}")
            except asyncio.QueueFull:
                logger.warning(f"[BROADCASTER] Queue full for chat {chat_id}, dropping event")
    
    def register_connection(self, chat_id: str):
        """Register a new SSE connection"""
        self.active_connections[chat_id] += 1
        logger.info(f"[BROADCASTER] SSE connection registered for {chat_id}, total: {self.active_connections[chat_id]}")
    
    def unregister_connection(self, chat_id: str):
        """Unregister an SSE connection"""
        if chat_id in self.active_connections:
            self.active_connections[chat_id] = max(0, self.active_connections[chat_id] - 1)
            logger.info(f"[BROADCASTER] SSE connection unregistered for {chat_id}, remaining: {self.active_connections[chat_id]}")
            
            # Clean up queue if no more connections
            if self.active_connections[chat_id] == 0 and chat_id in self.chat_queues:
                logger.info(f"[BROADCASTER] Cleaning up queue for {chat_id} (no more connections)")
                del self.chat_queues[chat_id]
                del self.active_connections[chat_id]

# Global broadcaster instance
event_broadcaster = SASEventBroadcaster()

async def _process_sas_events(
    chat_id: str, 
    message_content: str, 
    sas_app,
    flow_id: str = '',
    config: Optional[Dict[str, Any]] = None  # æ·»åŠ configå‚æ•°
):
    """
    Process SAS LangGraph execution and broadcast SSE events via global broadcaster
    """
    logger.info(f"[SAS Chat {chat_id}] Background task started. Input: {message_content[:100]}...")
    is_error = False
    error_data = {}
    final_state = None

    try:
        # å¦‚æœæ²¡æœ‰æä¾›å¤–éƒ¨configï¼Œåˆ™ä¸ºastream_eventsåˆ›å»ºä¸€ä¸ª
        if config is None:
            config = {"configurable": {"thread_id": chat_id}}
        else:
            # ç¡®ä¿å³ä½¿æä¾›äº†configï¼Œthread_idä¹Ÿå·²è®¾ç½®
            if "configurable" not in config:
                config["configurable"] = {}
            config["configurable"]["thread_id"] = chat_id
            
        # Prepare graph input, merging initial state values.
        # This ensures the graph starts with a clean, correct state for this run.
        logger.info(f"[SAS Chat {chat_id}] Preparing initial state for graph execution.")
        
        # ğŸ”§ è·å–å½“å‰æŒä¹…åŒ–çŠ¶æ€ï¼Œé¿å…ä¸å¿…è¦çš„é‡ç½®
        current_persistent_state = {}
        try:
            config = {"configurable": {"thread_id": chat_id}}
            current_state_snapshot = await sas_app.aget_state(config)
            if current_state_snapshot:
                current_persistent_state = get_checkpoint_values(current_state_snapshot)
                
                # ğŸ”§ æ·»åŠ è¯¦ç»†çš„çŠ¶æ€æ—¥å¿—ï¼Œå¸®åŠ©è¯Šæ–­é—®é¢˜
                tasks_data = current_persistent_state.get("sas_step1_generated_tasks")
                tasks_count = len(tasks_data) if tasks_data else 0
                logger.info(f"[SAS Chat {chat_id}] è·å–åˆ°æŒä¹…åŒ–çŠ¶æ€:")
                logger.info(f"  - dialog_state: {current_persistent_state.get('dialog_state')}")
                logger.info(f"  - task_list_accepted: {current_persistent_state.get('task_list_accepted', False)}")
                logger.info(f"  - module_steps_accepted: {current_persistent_state.get('module_steps_accepted', False)}")
                logger.info(f"  - sas_step1_generated_tasks count: {tasks_count}")
                logger.info(f"  - revision_iteration: {current_persistent_state.get('revision_iteration', 0)}")
                
                # ğŸ”§ å¦‚æœä»»åŠ¡åˆ—è¡¨å­˜åœ¨ï¼Œè®°å½•ä»»åŠ¡åç§°ä»¥ä¾¿è·Ÿè¸ª
                if tasks_data:
                    task_names = [task.get('name', 'unnamed') for task in tasks_data if isinstance(task, dict)]
                    logger.info(f"  - Task names: {task_names[:5]}{'...' if len(task_names) > 5 else ''}")
            else:
                logger.warning(f"[SAS Chat {chat_id}] æœªæ‰¾åˆ°ç°æœ‰çš„checkpointçŠ¶æ€")
        except Exception as state_get_error:
            logger.warning(f"[SAS Chat {chat_id}] è·å–æŒä¹…åŒ–çŠ¶æ€å¤±è´¥ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼: {state_get_error}")
        
        # ğŸ”§ æ ¹æ®å½“å‰æŒä¹…åŒ–çŠ¶æ€è®¾ç½®åˆå§‹å€¼ï¼Œé¿å…ä¸æ­£ç¡®çš„é‡ç½®
        # ç‰¹åˆ«æ³¨æ„ï¼šå¯¹äºç‰¹å®šçš„æ¶ˆæ¯ç±»å‹ï¼Œå¯èƒ½éœ€è¦ä¿ç•™æ›´å¤šçš„çŠ¶æ€
        preserved_tasks = current_persistent_state.get("sas_step1_generated_tasks", [])
        
        # ğŸ”§ åˆ é™¤äº†å…³é”®å­—æ‰¹å‡†é€»è¾‘ - åªæœ‰å‰ç«¯ç»¿è‰²æŒ‰é’®å¯ä»¥è§¦å‘æ‰¹å‡†
        # æ‰€æœ‰ç”¨æˆ·è¾“å…¥éƒ½å°†ä½œä¸ºæ™®é€šè¾“å…¥å¤„ç†ï¼Œä¸å†è¿›è¡Œå…³é”®å­—åŒ¹é…æ‰¹å‡†
        
        graph_input = {
            "dialog_state": "initial",
            "current_step_description": "Processing your request...",
            "current_user_request": message_content,
            "task_list_accepted": current_persistent_state.get("task_list_accepted", False),      # ğŸ”§ ä¿ç•™æŒä¹…åŒ–çŠ¶æ€
            "module_steps_accepted": current_persistent_state.get("module_steps_accepted", False), # ğŸ”§ ä¿ç•™æŒä¹…åŒ–çŠ¶æ€
            "revision_iteration": current_persistent_state.get("revision_iteration", 0),
            "sas_step1_generated_tasks": current_persistent_state.get("sas_step1_generated_tasks", []),
            "sas_step2_module_steps": current_persistent_state.get("sas_step2_module_steps", ""),
            "clarification_question": "",
            "user_input": message_content, # Pass the input through
            "current_chat_id": chat_id,  # For progress events
            "thread_id": chat_id,       # For state management
        }
        
        # ğŸ”§ è®°å½•å³å°†ä½¿ç”¨çš„graph_inputçŠ¶æ€
        final_tasks_count = len(graph_input["sas_step1_generated_tasks"]) if graph_input["sas_step1_generated_tasks"] else 0
        logger.info(f"[SAS Chat {chat_id}] å³å°†æ‰§è¡Œgraphï¼Œæœ€ç»ˆä»»åŠ¡æ•°é‡: {final_tasks_count}")
        if graph_input["sas_step1_generated_tasks"]:
            final_task_names = [task.get('name', 'unnamed') for task in graph_input["sas_step1_generated_tasks"] if isinstance(task, dict)]
            logger.info(f"[SAS Chat {chat_id}] æœ€ç»ˆä»»åŠ¡åç§°: {final_task_names[:5]}{'...' if len(final_task_names) > 5 else ''}")

        # ğŸ”§ åªä¿ç•™ç‰¹æ®Šçš„å‰ç«¯æŒ‰é’®è§¦å‘æ¶ˆæ¯å¤„ç†
        if message_content == "start_review":
            # ğŸ”§ æ–°å¢ï¼šå¤„ç†"å¼€å§‹å®¡æ ¸"æŒ‡ä»¤ï¼Œä¸“é—¨ç”¨äºä»ç”Ÿæˆå®ŒæˆçŠ¶æ€è¿›å…¥å®¡æ ¸çŠ¶æ€
            current_dialog_state = current_persistent_state.get('dialog_state')
            
            logger.info(f"[SAS Chat {chat_id}] æ”¶åˆ°start_reviewæŒ‡ä»¤ï¼Œå½“å‰çŠ¶æ€: {current_dialog_state}")
            
            if current_dialog_state == 'sas_step2_module_steps_generated_for_review':
                # ä»æ¨¡å—æ­¥éª¤ç”Ÿæˆå®ŒæˆçŠ¶æ€è¿›å…¥å®¡æ ¸çŠ¶æ€
                # ä¸æ”¹å˜dialog_stateï¼Œè®©review_and_refine_nodeå¤„ç†è½¬æ¢åˆ°å®¡æ ¸çŠ¶æ€
                graph_input["current_step_description"] = "Starting module steps review process..."
                logger.info(f"[SAS Chat {chat_id}] start_reviewæŒ‡ä»¤å°†è§¦å‘æ¨¡å—æ­¥éª¤å®¡æ ¸æµç¨‹")
            else:
                logger.warning(f"[SAS Chat {chat_id}] æ”¶åˆ°start_reviewä½†å½“å‰çŠ¶æ€ä¸æ”¯æŒ: {current_dialog_state}")
        
        # ğŸ”§ ä¿®å¤ï¼šå‰ç«¯ç»¿è‰²æŒ‰é’®ä¸“ç”¨æ‰¹å‡†é€»è¾‘ï¼ˆä½¿ç”¨æ­£ç¡®çš„çŠ¶æ€ï¼‰
        elif message_content == "FRONTEND_APPROVE_TASKS":
            current_dialog_state = current_persistent_state.get('dialog_state')
            if current_dialog_state == 'sas_awaiting_task_list_review':
                graph_input["task_list_accepted"] = True
                graph_input["user_input"] = None # Clear input to prevent re-processing
                graph_input["dialog_state"] = current_dialog_state # Keep state for routing
                logger.info(f"[SAS Chat {chat_id}] Frontend approved task list.")
            else:
                logger.warning(f"[SAS Chat {chat_id}] Frontend attempted to approve tasks but state was incorrect: {current_dialog_state}")
        
        elif message_content == "FRONTEND_APPROVE_MODULE_STEPS":
            current_dialog_state = current_persistent_state.get('dialog_state')
            if current_dialog_state == 'sas_awaiting_module_steps_review':
                graph_input["module_steps_accepted"] = True
                graph_input["user_input"] = None # Clear input
                graph_input["dialog_state"] = current_dialog_state # Keep state for routing
                logger.info(f"[SAS Chat {chat_id}] Frontend approved module steps.")
            else:
                logger.warning(f"[SAS Chat {chat_id}] Frontend attempted to approve module steps but state was incorrect: {current_dialog_state}")
        
        # ğŸ”§ æ–°å¢ï¼šè“è‰²æŒ‰é’®ä¿®æ”¹æ„è§é€»è¾‘ - é‡ç½®æ‰¹å‡†çŠ¶æ€
        elif message_content.startswith("FRONTEND_FEEDBACK:"):
            current_dialog_state = current_persistent_state.get('dialog_state')
            feedback_content = message_content.replace("FRONTEND_FEEDBACK:", "").strip()
            graph_input["current_user_request"] = feedback_content # Update the basis for generation

            if current_dialog_state == 'sas_awaiting_task_list_review':
                graph_input["task_list_accepted"] = False
                graph_input["module_steps_accepted"] = False
                graph_input["dialog_state"] = "user_input_to_task_list"
                logger.info(f"[SAS Chat {chat_id}] Task list feedback received. Resetting approvals and rerouting to task generation.")
            elif current_dialog_state == 'sas_awaiting_module_steps_review':
                graph_input["task_list_accepted"] = True
                graph_input["module_steps_accepted"] = False
                graph_input["dialog_state"] = "task_list_to_module_steps"
                logger.info(f"[SAS Chat {chat_id}] Module steps feedback received. Resetting module approval and rerouting to module step generation.")
            else:
                logger.info(f"[SAS Chat {chat_id}] General feedback received.")
        
        # ğŸ”§ æ‰€æœ‰å…¶ä»–ç”¨æˆ·è¾“å…¥éƒ½ä½œä¸ºæ™®é€šè¾“å…¥å¤„ç†ï¼Œä¸è¿›è¡Œä»»ä½•è‡ªåŠ¨æ‰¹å‡†
        else:
            logger.info(f"[SAS Chat {chat_id}] ç”¨æˆ·è¾“å…¥ä½œä¸ºæ™®é€šæ¶ˆæ¯å¤„ç†ï¼Œæ— è‡ªåŠ¨æ‰¹å‡†")

        # ä»å¤–éƒ¨ä¼ å…¥çš„configä¸­è·å–output_dir_path
        output_dir_path = config.get("output_dir_path")
        if output_dir_path:
            logger.info(f"[SAS Chat {chat_id}] Using output directory from config: {output_dir_path}")
            # å°†å…¶æ”¾å…¥graph_inputçš„configä¸­ï¼Œä»¥ä¾¿è¢«initialize_state_nodeä½¿ç”¨
            if "config" not in graph_input:
                graph_input["config"] = {}
            graph_input["config"]["OUTPUT_DIR_PATH"] = output_dir_path

        logger.info(f"[SAS Chat {chat_id}] Invoking SAS graph with astream_events...")
        
        async for event in sas_app.astream_events(graph_input, config=config, version="v2"):
            event_name = event.get("event")
            event_data = event.get("data", {})
            run_name = event.get("name", "unknown_run")

            logger.debug(f"[SAS Chat {chat_id}] Received event: '{event_name}' from '{run_name}'")
            
            if event_name == "on_chat_model_stream":
                chunk = event_data.get("chunk")
                if chunk and isinstance(chunk, AIMessageChunk) and chunk.content:
                    token = chunk.content
                    logger.debug(f"[SAS Chat {chat_id}] LLM Token: '{token}'")
                    await event_broadcaster.broadcast_event(chat_id, {"type": "token", "data": token})
            
            elif event_name == "on_tool_start":
                tool_name = event_data.get("name")
                tool_input = event_data.get("input")
                logger.info(f"[SAS Chat {chat_id}] Tool Start: '{tool_name}'")
                await event_broadcaster.broadcast_event(chat_id, {"type": "tool_start", "data": {"name": tool_name, "input": tool_input}})
                
            elif event_name == "on_tool_end":
                tool_name = event_data.get("name")
                tool_output = event_data.get("output")
                logger.info(f"[SAS Chat {chat_id}] Tool End: '{tool_name}'")
                await event_broadcaster.broadcast_event(chat_id, {"type": "tool_end", "data": {"name": tool_name, "output_summary": str(tool_output)[:200]}})
            
            elif event_name == "on_chain_end":
                outputs_from_chain = event_data.get("output", {})
                logger.info(f"[SAS Chat {chat_id}] ğŸš¨ Chain End: '{run_name}'. Output keys: {list(outputs_from_chain.keys()) if isinstance(outputs_from_chain, dict) else 'Not a dict'}")
                
                should_sync = False
                sync_reason = ""
                has_error_state = False
                
                # Check if this is the main graph or SAS-related chain
                if run_name in ["__graph__", "sas_user_input_to_task_list", "sas_review_and_refine", "sas_task_list_to_module_steps"] or "sas" in run_name.lower():
                    if isinstance(outputs_from_chain, dict):
                        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯çŠ¶æ€
                        if outputs_from_chain.get("is_error", False) or outputs_from_chain.get("dialog_state") == "error" or outputs_from_chain.get("completion_status") == "error":
                            has_error_state = True
                            error_message = outputs_from_chain.get("error_message", "Unknown error occurred in SAS processing")
                            logger.error(f"[SAS Chat {chat_id}] ğŸš¨ æ£€æµ‹åˆ°èŠ‚ç‚¹é”™è¯¯çŠ¶æ€: {error_message}")
                            
                            # ç«‹å³å‘é€é”™è¯¯äº‹ä»¶åˆ°å‰ç«¯
                            error_data = {
                                "message": error_message, 
                                "stage": f"sas_node_error_in_{run_name}",
                                "dialog_state": outputs_from_chain.get("dialog_state"),
                                "completion_status": outputs_from_chain.get("completion_status")
                            }
                            await event_broadcaster.broadcast_event(chat_id, {"type": "error", "data": error_data})
                            is_error = True
                            
                        important_keys = [
                            'sas_step1_generated_tasks',
                            'dialog_state',
                            'completion_status',
                            'task_list_accepted',
                            'module_steps_accepted',
                            'clarification_question'
                        ]
                        
                        found_keys = [key for key in important_keys if key in outputs_from_chain]
                        if found_keys:
                            should_sync = True
                            sync_reason = f"SASçŠ¶æ€æ›´æ–° (run_name: {run_name}, found_keys: {found_keys}, has_error: {has_error_state})"
                            final_state = outputs_from_chain
                            logger.info(f"[SAS Chat {chat_id}] ğŸ¯ è§¦å‘åŒæ­¥: {sync_reason}")
                
                if should_sync and flow_id and final_state:
                    try:
                        # å‡†å¤‡å‰ç«¯æ›´æ–°æ•°æ®ï¼ˆä¸æ¶‰åŠFlowæ¨¡å‹ï¼Œéµå¾ªå•ä¸€æ•°æ®æºåŸåˆ™ï¼‰
                        frontend_update_result = await _prepare_frontend_update(final_state, flow_id)
                        
                        if frontend_update_result and frontend_update_result.get("needs_frontend_update"):
                            logger.info(f"[SAS Chat {chat_id}] ğŸ¯ å‘é€agent_state_updatedäº‹ä»¶åˆ°å‰ç«¯")
                            await event_broadcaster.broadcast_event(chat_id, {
                                "type": "agent_state_updated", 
                                "data": {
                                    "message": "SAS agent state updated",
                                    "update_types": frontend_update_result.get("update_types", []),
                                    "flow_id": flow_id,
                                    "agent_state": frontend_update_result.get("updated_agent_state", {}),
                                    "trigger": "sas_chain_end"
                                }
                            })
                            # ç»™å‰ç«¯æ—¶é—´å¤„ç†è¿™ä¸ªé‡è¦äº‹ä»¶
                            await asyncio.sleep(0.1)
                        else:
                            logger.info(f"[SAS Chat {chat_id}] ğŸ¯ çŠ¶æ€å¤„ç†å®Œæˆä½†æ— éœ€å‰ç«¯æ›´æ–°")
                            # å³ä½¿æ— é‡è¦å­—æ®µå˜åŒ–ï¼Œä¹Ÿå‘é€åŸºæœ¬çš„çŠ¶æ€ä¿¡æ¯è®©å‰ç«¯çŸ¥é“å¤„ç†å·²å®Œæˆ
                            if final_state and final_state.get("dialog_state"):
                                await event_broadcaster.broadcast_event(chat_id, {
                                    "type": "agent_state_updated",
                                    "data": {
                                        "message": "SAS state processing completed",
                                        "flow_id": flow_id,
                                        "agent_state": {
                                            "dialog_state": final_state.get("dialog_state"),
                                            "clarification_question": final_state.get("clarification_question"),
                                            "sas_step1_generated_tasks": final_state.get("sas_step1_generated_tasks"),
                                            "task_list_accepted": final_state.get("task_list_accepted"),
                                            "module_steps_accepted": final_state.get("module_steps_accepted"),
                                            "completion_status": final_state.get("completion_status")
                                        },
                                        "trigger": "sas_state_completed"
                                    }
                                })
                                # ç»™å‰ç«¯æ—¶é—´å¤„ç†è¿™ä¸ªäº‹ä»¶
                                await asyncio.sleep(0.1)
                    except Exception as frontend_update_error:
                        logger.error(f"[SAS Chat {chat_id}] ğŸ¯ å‰ç«¯æ›´æ–°è¿‡ç¨‹ä¸­å‡ºé”™: {frontend_update_error}", exc_info=True)
            
            elif event_name in ["on_chain_error", "on_llm_error", "on_tool_error"]:
                error_content = str(event_data.get("error", "Unknown error"))
                logger.error(f"[SAS Chat {chat_id}] Error event '{event_name}' from '{run_name}': {error_content}")
                is_error = True
                error_data = {"message": f"Error in {run_name}: {error_content}", "stage": f"error_in_{run_name}"}
                await event_broadcaster.broadcast_event(chat_id, {"type": "error", "data": error_data})

    except Exception as e:
        is_error = True
        error_message = f"Error during SAS LangGraph processing: {str(e)}"
        logger.error(f"[SAS Chat {chat_id}] {error_message}", exc_info=True)
        error_data = {"message": error_message, "stage": "sas_execution"}
        try:
            await event_broadcaster.broadcast_event(chat_id, {"type": "error", "data": error_data})
        except Exception as qe:
            logger.error(f"[SAS Chat {chat_id}] Failed to broadcast error: {qe}")

    finally:
        try:
            # ç»™å‰ç«¯ä¸€ç‚¹æ—¶é—´å¤„ç†ä¹‹å‰çš„äº‹ä»¶ï¼Œç‰¹åˆ«æ˜¯agent_state_updatedäº‹ä»¶
            await asyncio.sleep(0.5)  # 500mså»¶è¿Ÿç¡®ä¿é‡è¦äº‹ä»¶è¢«å¤„ç†
            
            # ğŸ”§ ä¿®å¤ï¼šä»æ£€æŸ¥ç‚¹è·å–æœ€æ–°çŠ¶æ€ï¼Œè€Œä¸æ˜¯ä½¿ç”¨å¯èƒ½è¿‡æ—¶çš„ final_state
            latest_state = None
            try:
                config = {"configurable": {"thread_id": chat_id}}
                current_checkpoint = await sas_app.aget_state(config)
                if current_checkpoint:
                    latest_state = get_checkpoint_values(current_checkpoint)
                    logger.info(f"[SAS Chat {chat_id}] ğŸ”§ è·å–æœ€æ–°æ£€æŸ¥ç‚¹çŠ¶æ€ï¼Œdialog_state: {latest_state.get('dialog_state') if latest_state else 'None'}")
            except Exception as e:
                logger.warning(f"[SAS Chat {chat_id}] è·å–æœ€æ–°æ£€æŸ¥ç‚¹çŠ¶æ€å¤±è´¥: {e}")
                # å¦‚æœè·å–å¤±è´¥ï¼Œå›é€€åˆ°ä½¿ç”¨ final_state
                latest_state = final_state
            
            # ä¸å†å‘é€stream_endäº‹ä»¶ï¼Œä¿æŒSSEè¿æ¥å¼€å¯
            # logger.info(f"[SAS Chat {chat_id}] Broadcasting stream_end event.")
            # await event_broadcaster.broadcast_event(chat_id, {"type": "stream_end", "data": {"chat_id": chat_id}})
            # logger.info(f"[SAS Chat {chat_id}] Stream end event broadcast.")
            
            # å‘é€å¤„ç†å®Œæˆäº‹ä»¶ï¼Œä½†ä¿æŒè¿æ¥ï¼Œå¹¶åŒ…å«æœ€ç»ˆçŠ¶æ€
            logger.info(f"[SAS Chat {chat_id}] Broadcasting processing_complete event (keeping connection alive).")
            
            # ğŸ”§ æ„å»º processing_complete äº‹ä»¶æ•°æ®
            event_data = {
                "type": "processing_complete",
                "data": {
                    "chat_id": chat_id,
                    "message": "SAS processing completed, connection remains open for future events"
                }
            }
            
            # å¦‚æœæœ‰æœ€ç»ˆçŠ¶æ€ï¼ŒåŒ…å«åœ¨äº‹ä»¶ä¸­ï¼ˆä¼˜å…ˆä½¿ç”¨æœ€æ–°çš„æ£€æŸ¥ç‚¹çŠ¶æ€ï¼‰
            state_to_send = latest_state if latest_state else final_state
            if state_to_send and isinstance(state_to_send, dict):
                # ğŸ”§ ä¿®å¤ï¼šåºåˆ—åŒ– Pydantic æ¨¡å‹å¯¹è±¡ä»¥é¿å… JSON åºåˆ—åŒ–é”™è¯¯
                def serialize_pydantic_objects(obj):
                    """å®‰å…¨åœ°åºåˆ—åŒ– Pydantic æ¨¡å‹å¯¹è±¡"""
                    if hasattr(obj, 'model_dump'):
                        return obj.model_dump()
                    elif hasattr(obj, 'dict'):
                        return obj.dict()
                    elif isinstance(obj, list):
                        return [serialize_pydantic_objects(item) for item in obj]
                    elif isinstance(obj, dict):
                        return {k: serialize_pydantic_objects(v) for k, v in obj.items()}
                    else:
                        return obj
                
                # åºåˆ—åŒ– sas_step1_generated_tasks ä¸­çš„ TaskDefinition å¯¹è±¡
                sas_step1_tasks = state_to_send.get("sas_step1_generated_tasks")
                if sas_step1_tasks:
                    sas_step1_tasks = serialize_pydantic_objects(sas_step1_tasks)
                
                event_data["data"]["final_state"] = {
                    "dialog_state": state_to_send.get("dialog_state"),
                    "sas_step1_generated_tasks": sas_step1_tasks,
                    "task_list_accepted": state_to_send.get("task_list_accepted"),
                    "module_steps_accepted": state_to_send.get("module_steps_accepted"),
                    "completion_status": state_to_send.get("completion_status"),
                    "clarification_question": state_to_send.get("clarification_question")
                }
                logger.info(f"[SAS Chat {chat_id}] Including final state in processing_complete: {state_to_send.get('dialog_state')}")
            
            await event_broadcaster.broadcast_event(chat_id, event_data)
            
        except Exception as qe:
            logger.error(f"[SAS Chat {chat_id}] Failed to broadcast processing_complete: {qe}")
        
        logger.info(f"[SAS Chat {chat_id}] Background task completed, but SSE connection remains open.")

@router.post("/{chat_id}/events")
async def sas_chat_events_post(
    chat_id: str,
    request: Request,
    sas_app = Depends(get_sas_app),
    user: schemas.User = Depends(verify_flow_access)
):
    """
    SAS POSTç«¯ç‚¹ï¼šå¯åŠ¨SASå¤„ç†å¹¶è¿”å›SSEæµ
    """
    # å¤„ç†POSTè¯·æ±‚ï¼šå¯åŠ¨SASå¤„ç†
    try:
        body = await request.json()
        message_content = body.get("input")

        if message_content is None:
            raise HTTPException(status_code=400, detail="Missing 'input' in request body")

        logger.info(f"SAS POST for chat_id/thread_id: {chat_id}, input: {message_content[:100]}...")

        # Extract flow_id from chat_id if possible (for state sync)
        flow_id = chat_id  # Assuming chat_id is flow_id for SAS
        
        # Start background task to process SAS events using the global broadcaster
        asyncio.create_task(_process_sas_events(chat_id, message_content, sas_app, flow_id))
        
    except json.JSONDecodeError:
        raise HTTPException(status_code=400, detail="Invalid JSON in request body.")
    except Exception as e:
        logger.error(f"Error in POST /sas/{chat_id}/events: {e}", exc_info=True)
        # å³ä½¿å¯åŠ¨å¤„ç†å¤±è´¥ï¼Œä¹Ÿå°è¯•æä¾›SSEæµæ¥å‘é€é”™è¯¯ä¿¡æ¯
        await event_broadcaster.broadcast_event(chat_id, {
            "type": "error", 
            "data": {"message": f"Failed to start processing: {str(e)}", "stage": "startup"}
        })

    # è¿”å›SSEæµ
    logger.info(f"SAS SSE stream for chat_id/thread_id: {chat_id}")
    
    # Register this SSE connection
    event_broadcaster.register_connection(chat_id)
    
    async def event_generator():
        try:
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ ‡å‡†SSEæ ¼å¼å‘é€èµ·å§‹äº‹ä»¶
            yield f"event: start\ndata: {json.dumps({'run_id': chat_id})}\n\n"
            
            # Get or create event queue for this chat
            event_queue = await event_broadcaster.get_or_create_queue(chat_id)
            
            while True:
                try:
                    # Wait for events from the broadcaster queue
                    event_item = await asyncio.wait_for(event_queue.get(), timeout=30.0)
                    
                    # æ£€æŸ¥æ˜¯å¦æ”¶åˆ°æ–­å¼€è¿æ¥çš„ä¿¡å·
                    if event_item.get("type") == "connection_close":
                        logger.info(f"[SAS Events {chat_id}] Received connection_close signal")
                        yield f"event: connection_close\ndata: {json.dumps(event_item.get('data', {}))}\n\n"
                        break
                    
                    # ç§»é™¤stream_endçš„ç‰¹æ®Šå¤„ç†ï¼Œè®©è¿æ¥ä¿æŒå¼€å¯
                    # if event_item.get("type") == "stream_end":
                    #     logger.info(f"[SAS Events {chat_id}] Received stream end")
                    #     # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ ‡å‡†SSEæ ¼å¼
                    #     yield f"event: stream_end\ndata: {json.dumps(event_item.get('data', {}))}\n\n"
                    #     break
                    
                    # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ ‡å‡†SSEæ ¼å¼å‘é€æ‰€æœ‰äº‹ä»¶ï¼ˆåŒ…æ‹¬processing_completeï¼‰
                    event_type = event_item.get("type", "message")
                    event_data = event_item.get("data", {})
                    logger.debug(f"[SAS Events {chat_id}] Sending event '{event_type}' with data: {str(event_data)[:100]}...")
                    yield f"event: {event_type}\ndata: {json.dumps(event_data)}\n\n"
                        
                except asyncio.TimeoutError:
                    logger.debug(f"[SAS Events {chat_id}] SSE timeout, sending ping")
                    # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ ‡å‡†SSEæ ¼å¼å‘é€ping
                    yield f"event: ping\ndata: {json.dumps({'timestamp': time.time()})}\n\n"
                    continue
                        
        except Exception as stream_exc:
            logger.error(f"[SAS Events {chat_id}] SSEæµé”™è¯¯: {stream_exc}", exc_info=True)
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ ‡å‡†SSEæ ¼å¼å‘é€é”™è¯¯
            yield f"event: error\ndata: {json.dumps({'error': str(stream_exc)})}\n\n"
        finally:
            logger.info(f"[SAS Events {chat_id}] SSEäº‹ä»¶æµç»“æŸ")
            # Unregister connection when SSE ends
            event_broadcaster.unregister_connection(chat_id)
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ ‡å‡†SSEæ ¼å¼å‘é€ç»“æŸäº‹ä»¶
            yield f"event: end\ndata: {json.dumps({})}\n\n"

    return StreamingResponse(event_generator(), media_type="text/event-stream")

@router.get("/{chat_id}/events")
async def sas_chat_events_get(
    chat_id: str,
    request: Request,
    sas_app = Depends(get_sas_app),
    user: schemas.User = Depends(verify_flow_access)
):
    """
    SAS GETç«¯ç‚¹ï¼šè¿æ¥åˆ°ç°æœ‰çš„SSEæµ
    """
    logger.info(f"SAS GET SSE stream for chat_id/thread_id: {chat_id}")
    
    # Register this SSE connection
    event_broadcaster.register_connection(chat_id)
    
    async def event_generator():
        try:
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ ‡å‡†SSEæ ¼å¼å‘é€èµ·å§‹äº‹ä»¶
            yield f"event: start\ndata: {json.dumps({'run_id': chat_id})}\n\n"
            
            # Get or create event queue for this chat
            event_queue = await event_broadcaster.get_or_create_queue(chat_id)
            
            while True:
                try:
                    # Wait for events from the broadcaster queue
                    event_item = await asyncio.wait_for(event_queue.get(), timeout=30.0)
                    
                    # æ£€æŸ¥æ˜¯å¦æ”¶åˆ°æ–­å¼€è¿æ¥çš„ä¿¡å·
                    if event_item.get("type") == "connection_close":
                        logger.info(f"[SAS Events {chat_id}] Received connection_close signal")
                        yield f"event: connection_close\ndata: {json.dumps(event_item.get('data', {}))}\n\n"
                        break
                    
                    # ç§»é™¤stream_endçš„ç‰¹æ®Šå¤„ç†ï¼Œè®©è¿æ¥ä¿æŒå¼€å¯
                    # if event_item.get("type") == "stream_end":
                    #     logger.info(f"[SAS Events {chat_id}] Received stream end")
                    #     # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ ‡å‡†SSEæ ¼å¼
                    #     yield f"event: stream_end\ndata: {json.dumps(event_item.get('data', {}))}\n\n"
                    #     break
                    
                    # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ ‡å‡†SSEæ ¼å¼å‘é€æ‰€æœ‰äº‹ä»¶ï¼ˆåŒ…æ‹¬processing_completeï¼‰
                    event_type = event_item.get("type", "message")
                    event_data = event_item.get("data", {})
                    logger.debug(f"[SAS Events {chat_id}] Sending event '{event_type}' with data: {str(event_data)[:100]}...")
                    yield f"event: {event_type}\ndata: {json.dumps(event_data)}\n\n"
                        
                except asyncio.TimeoutError:
                    logger.debug(f"[SAS Events {chat_id}] SSE timeout, sending ping")
                    # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ ‡å‡†SSEæ ¼å¼å‘é€ping
                    yield f"event: ping\ndata: {json.dumps({'timestamp': time.time()})}\n\n"
                    continue
                        
        except Exception as stream_exc:
            logger.error(f"[SAS Events {chat_id}] SSEæµé”™è¯¯: {stream_exc}", exc_info=True)
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ ‡å‡†SSEæ ¼å¼å‘é€é”™è¯¯
            yield f"event: error\ndata: {json.dumps({'error': str(stream_exc)})}\n\n"
        finally:
            logger.info(f"[SAS Events {chat_id}] SSEäº‹ä»¶æµç»“æŸ")
            # Unregister connection when SSE ends
            event_broadcaster.unregister_connection(chat_id)
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ ‡å‡†SSEæ ¼å¼å‘é€ç»“æŸäº‹ä»¶
            yield f"event: end\ndata: {json.dumps({})}\n\n"

    return StreamingResponse(event_generator(), media_type="text/event-stream")

@router.post("/{chat_id}/update-state")
async def sas_update_state(
    chat_id: str,
    request: Request,
    checkpointer: AsyncPostgresSaver = Depends(get_checkpointer), # ç›´æ¥æ³¨å…¥çœŸæ­£çš„Checkpointer
    user: schemas.User = Depends(verify_flow_access)
):
    """
    Updates the state of a SAS LangGraph flow without triggering further execution.
    This is a 'write-only' operation used for UI-driven state saves.
    """
    try:
        state_update_payload = await request.json()
        
        # æœ€ç»ˆä¿®å¤ï¼šç¡®ä¿ config å­—å…¸ä¸­åŒ…å« 'checkpoint_ns'
        config = {
            "configurable": {
                "thread_id": chat_id,
                "checkpoint_ns": ""  # ä¸º aput æ–¹æ³•æä¾›å¿…éœ€çš„é”®
            }
        }

        # æ–¹æ¡ˆæ ¸å¿ƒï¼šä¸º checkpointer.aput() æä¾›æ‰€æœ‰å¿…éœ€çš„å‚æ•°
        # 1. è·å–å½“å‰æœ€æ–°çŠ¶æ€çš„å®Œæ•´å¿«ç…§å…ƒç»„
        current_checkpoint_tuple = await checkpointer.aget_tuple(config)
        if not current_checkpoint_tuple:
            raise HTTPException(status_code=404, detail=f"Flow with chat_id {chat_id} not found.")

        current_checkpoint = current_checkpoint_tuple.checkpoint
        current_metadata = current_checkpoint_tuple.metadata
        
        # 2. å°†å‰ç«¯çš„å±€éƒ¨æ›´æ–°åˆå¹¶åˆ°å®Œæ•´çŠ¶æ€çš„ 'values' ä¸­
        updated_values = {**current_checkpoint['channel_values'], **state_update_payload}

        # 3. æ„é€ ä¸€ä¸ªæ–°çš„ã€å®Œæ•´çš„æ£€æŸ¥ç‚¹ (Checkpoint)
        new_checkpoint = {
            **current_checkpoint,
            "channel_values": updated_values
        }

        # 4. æ„é€  aput éœ€è¦çš„ metadata å’Œ new_versions å‚æ•°
        #    æˆ‘ä»¬å°†è¿™æ¬¡å†™å…¥æ˜ç¡®æ ‡è®°ä¸ºä¸€æ¬¡ 'update'
        updated_metadata = {**current_metadata, "source": "update"}
        
        #    å¯¹äº new_versionsï¼Œæˆ‘ä»¬å‡è®¾è¿™æ¬¡æ‰‹åŠ¨æ›´æ–°ä¸æ”¹å˜ç‰ˆæœ¬é€»è¾‘ï¼Œ
        #    å› æ­¤ç›´æ¥å¤ç”¨å½“å‰çš„ channel_versionsã€‚
        #    è¿™æ˜¯æœ€å®‰å…¨çš„åšæ³•ï¼Œå› ä¸ºå®ƒç¡®ä¿äº†ä¸‹æ¬¡å›¾æ‰§è¡Œæ—¶ï¼Œç‰ˆæœ¬ä¾èµ–ä¾ç„¶æ­£ç¡®ã€‚
        current_versions = current_checkpoint['channel_versions']

        # 5. è°ƒç”¨ checkpointer.aputï¼Œå¹¶ä¼ å…¥æ‰€æœ‰å››ä¸ªå¿…éœ€çš„å‚æ•°
        updated_config = await checkpointer.aput(
            config, 
            new_checkpoint, 
            updated_metadata,
            current_versions
        )

        logger.info(f"SAS update-state for thread {chat_id}: {len(str(state_update_payload))} bytes updated via checkpointer.aput.")
        logger.debug(f"New checkpoint config: {updated_config}")
        
        return updated_config

    except json.JSONDecodeError:
        raise HTTPException(status_code=400, detail="Invalid JSON in request body.")
    except Exception as e:
        logger.error(f"Error in /sas/{chat_id}/update-state: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/{chat_id}/state")
async def sas_get_state(
    chat_id: str,
    sas_app = Depends(get_sas_app),
    user: schemas.User = Depends(verify_flow_access)
):
    """
    Retrieves the current state of a SAS LangGraph flow.
    """
    try:
        # ç¡®ä¿ç”¨æˆ·æƒé™éªŒè¯å®Œæˆ
        if not user:
            raise HTTPException(status_code=401, detail="User authentication required")
        
        print(f"ğŸ”§ [DEBUG] SAS get-state for chat_id/thread_id: {chat_id}, user: {user.username if hasattr(user, 'username') else 'unknown'}")
        
        config = {"configurable": {"thread_id": chat_id}}
        
        # æ·»åŠ é‡è¯•æœºåˆ¶ï¼Œé˜²æ­¢æ—¶åºé—®é¢˜
        max_retries = 3
        retry_delay = 0.1
        current_checkpoint = None
        
        for attempt in range(max_retries):
            try:
                current_checkpoint = await sas_app.aget_state(config)
                if current_checkpoint:
                    break
                    
                logger.debug(f"Attempt {attempt + 1}: No checkpoint found for thread {chat_id}, retrying...")
                if attempt < max_retries - 1:
                    await asyncio.sleep(retry_delay)
                    retry_delay *= 2  # æŒ‡æ•°é€€é¿
                    
            except Exception as retry_error:
                logger.warning(f"Attempt {attempt + 1} failed for thread {chat_id}: {retry_error}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(retry_delay)
                    retry_delay *= 2
                else:
                    # è®°å½•æœ€ç»ˆå¤±è´¥çš„è¯¦ç»†ä¿¡æ¯
                    logger.error(f"Failed to get state for thread {chat_id} after {max_retries} attempts: {retry_error}")
                    raise retry_error
        
        logger.debug(f"Current checkpoint type: {type(current_checkpoint)}")
        logger.debug(f"Current checkpoint exists: {current_checkpoint is not None}")
        
        if current_checkpoint:
            # ä½¿ç”¨è¾…åŠ©å‡½æ•°å®‰å…¨åœ°è·å–values
            try:
                checkpoint_values = get_checkpoint_values(current_checkpoint)
                logger.debug(f"Successfully got checkpoint values: {bool(checkpoint_values)}")
                
                if checkpoint_values:
                    dialog_state = checkpoint_values.get('dialog_state')
                    tasks = checkpoint_values.get('sas_step1_generated_tasks')
                    current_user_request = checkpoint_values.get('current_user_request')
                    
                    logger.debug(f"Dialog state: {dialog_state}")
                    logger.debug(f"Tasks count: {len(tasks) if tasks else 0}")
                    logger.debug(f"Has user request: {bool(current_user_request)}")
                    
                    if tasks:
                        logger.info(f"Found {len(tasks)} tasks for thread {chat_id}")
                    else:
                        logger.info(f"No tasks found for thread {chat_id}")
                else:
                    logger.warning(f"Failed to get checkpoint values for thread {chat_id}")
            except Exception as values_error:
                logger.error(f"Error getting checkpoint values for thread {chat_id}: {values_error}")
                # å³ä½¿è·å–valueså¤±è´¥ï¼Œä»ç„¶è¿”å›checkpointï¼Œè®©å‰ç«¯å¤„ç†
        else:
            logger.warning(f"No checkpoint found for thread {chat_id} after {max_retries} attempts")
        
        if not current_checkpoint:
            # è¿”å›ä¸€ä¸ªé»˜è®¤çš„ç©ºçŠ¶æ€è€Œä¸æ˜¯404é”™è¯¯ï¼Œé¿å…å‰ç«¯å¤„ç†é—®é¢˜
            logger.info(f"Returning default empty state for thread {chat_id}")
            return {
                "values": {
                    "dialog_state": "initial",
                    "messages": [],
                    "task_list_accepted": False,
                    "module_steps_accepted": False,
                    "current_step_description": "No state found, using default initial state"
                },
                "config": {"configurable": {"thread_id": chat_id}},
                "metadata": {"source": "default_empty_state"}
            }
            
        return current_checkpoint
        
    except HTTPException:
        # é‡æ–°æŠ›å‡ºHTTPå¼‚å¸¸
        raise
    except Exception as e:
        error_msg = f"Error in /sas/{chat_id}/state: {e}"
        logger.error(error_msg, exc_info=True)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æƒé™ç›¸å…³çš„é”™è¯¯
        if "permission" in str(e).lower() or "unauthorized" in str(e).lower() or "forbidden" in str(e).lower():
            raise HTTPException(status_code=403, detail=f"Permission denied for thread_id {chat_id}")
        
        # å¯¹äºå…¶ä»–é”™è¯¯ï¼Œè¿”å›ä¸€ä¸ªæ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯
        raise HTTPException(status_code=500, detail=f"Unable to retrieve state for thread_id {chat_id}: {str(e)[:100]}")

# Further considerations:
# - Authentication/Authorization (important for production)
# - Error handling and logging
# - Input and Output Pydantic models for validation and serialization

@router.post("/{chat_id}/disconnect-sse")
async def disconnect_sse_connection(
    chat_id: str,
    user: schemas.User = Depends(verify_flow_access)
):
    """
    ä¸»åŠ¨æ–­å¼€æŒ‡å®šchat_idçš„SSEè¿æ¥
    ç”¨äºç”¨æˆ·åˆ‡æ¢flowæˆ–å…³é—­é¡µé¢æ—¶æ¸…ç†è¿æ¥
    """
    try:
        # å‘é€æ–­å¼€ä¿¡å·åˆ°æ‰€æœ‰è¯¥chat_idçš„SSEè¿æ¥
        await event_broadcaster.broadcast_event(chat_id, {
            "type": "connection_close",
            "data": {
                "chat_id": chat_id,
                "reason": "client_requested_disconnect",
                "message": "SSE connection closed by client request"
            }
        })
        
        logger.info(f"Disconnect signal sent for chat {chat_id} SSE connections")
        return {"success": True, "message": f"Disconnect signal sent for chat {chat_id}"}
        
    except Exception as e:
        logger.error(f"Failed to send disconnect signal for chat {chat_id}: {e}")
        return {"success": False, "message": f"Failed to disconnect: {str(e)}"}

@router.get("/health")
async def health_check():
    """ç®€å•çš„å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {"status": "ok", "message": "SAS Chat is healthy"}

@router.post("/{flow_id}/reset-stuck-state", response_model=schemas.SuccessResponse)
async def reset_stuck_state(
    flow_id: str,
    sas_app = Depends(get_sas_app),
    user: schemas.User = Depends(verify_flow_access_by_flow_id)
):
    """
    é‡ç½®å¡ä½çš„å¤„ç†çŠ¶æ€ï¼Œé€šè¿‡checkpointå›é€€åˆ°æœ€è¿‘çš„ç¨³å®šçŠ¶æ€
    """
    try:
        config = {"configurable": {"thread_id": flow_id}}
        
        # è·å–å½“å‰çŠ¶æ€
        current_state_snapshot = await sas_app.aget_state(config)
        if not current_state_snapshot:
            raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°è¯¥æµç¨‹çš„çŠ¶æ€")
        
        current_state = get_checkpoint_values(current_state_snapshot)
        current_dialog_state = current_state.get('dialog_state')
        is_error_state = current_state.get('is_error', False)
        
        # Check if the state is considered stuck
        stuck_states = [
            'generation_failed',
            'sas_generating_individual_xmls',
            'parameter_mapping',
            'merge_xml',
            'error'
        ]
        
        if current_dialog_state not in stuck_states and not is_error_state:
            return {"success": True, "message": "Current state does not require a reset."}
        
        logger.info(f"Resetting stuck state for flow {flow_id} from: {current_dialog_state}")
        
        # è·å–checkpointå†å²
        checkpoint_history = []
        try:
            async for checkpoint_tuple in sas_app.aget_state_history(config):
                if checkpoint_tuple:  # ç®€åŒ–æ£€æŸ¥ï¼ŒStateSnapshotå¯¹è±¡åº”è¯¥æ€»æ˜¯æœ‰æ•ˆ
                    checkpoint_history.append(checkpoint_tuple)
        except Exception as history_error:
            logger.error(f"è·å–checkpointå†å²å¤±è´¥: {history_error}")
            # å¦‚æœæ— æ³•è·å–å†å²ï¼Œåˆ›å»ºå¹²å‡€çš„åˆå§‹çŠ¶æ€
            checkpoint_history = []
        
        if len(checkpoint_history) < 2:
            # æ²¡æœ‰å†å²ï¼Œåˆ›å»ºå¹²å‡€çš„åˆå§‹çŠ¶æ€
            initial_state_dict = {
                "messages": [],
                "dialog_state": "initial",
                "config": {},
                "task_list_accepted": False,
                "module_steps_accepted": False,
                "is_error": False,
                "language": "zh",
                "relation_xml_content": "",
                "relation_xml_path": "",
                "revision_iteration": 0,
                "generated_node_xmls": [],
                "merged_xml_file_paths": [],
                "current_step_description": "Reset to clean initial state (no history found)"
            }
            
            await sas_app.aupdate_state(config, initial_state_dict)
            
            return {
                "success": True, 
                "message": f"å·²é‡ç½®åˆ°å¹²å‡€çš„åˆå§‹çŠ¶æ€ (ä» {current_dialog_state})"
            }
        
        # Define stable states with priority for rollback
        stable_states_priority = [
            'sas_awaiting_module_steps_review',
            'sas_awaiting_task_list_review',
            'initial'
        ]
        
        # Find the most recent stable checkpoint
        target_checkpoint = None
        target_priority = float('inf')
        
        for i in range(1, len(checkpoint_history)):
            checkpoint_tuple = checkpoint_history[i]
            
            # æ­£ç¡®è·å–checkpointçš„çŠ¶æ€æ•°æ® - éœ€è¦é€šè¿‡configé‡æ–°è·å–å®Œæ•´çŠ¶æ€
            try:
                checkpoint_config = checkpoint_tuple.config
                checkpoint_data = await sas_app.aget_state(checkpoint_config)
                if checkpoint_data:
                    checkpoint_values = get_checkpoint_values(checkpoint_data)
                    dialog_state = checkpoint_values.get('dialog_state')
                    is_error = checkpoint_values.get('is_error', False)
                    
                    # å¯»æ‰¾ä¸€ä¸ªç¨³å®šä¸”æ— é”™è¯¯çš„checkpoint
                    if dialog_state and dialog_state in stable_states_priority and not is_error:
                        priority = stable_states_priority.index(dialog_state)
                        if priority < target_priority:
                            target_checkpoint = checkpoint_tuple
                            target_priority = priority
                            logger.info(f"Found better rollback target: {dialog_state} (priority {priority})")
                            
                            # å¦‚æœæ‰¾åˆ°äº†æœ€é«˜ä¼˜å…ˆçº§çš„çŠ¶æ€ï¼Œå°±åœæ­¢æœç´¢
                            if priority == 0:
                                break
                    else:
                        logger.debug(f"Checkpoint {i} not suitable: state={dialog_state}, error={is_error}")
                else:
                    logger.warning(f"Could not get state data for checkpoint {i}")
            except Exception as e:
                logger.warning(f"Error checking checkpoint {i}: {e}")
                continue
        
        if not target_checkpoint:
            # æ²¡æœ‰æ‰¾åˆ°ç¨³å®šcheckpointï¼Œåˆ›å»ºåˆå§‹çŠ¶æ€
            initial_state_dict = {
                "messages": [],
                "dialog_state": "initial",
                "config": {},
                "task_list_accepted": False,
                "module_steps_accepted": False,
                "is_error": False,
                "language": "zh",
                "relation_xml_content": "",
                "relation_xml_path": "",
                "revision_iteration": 0,
                "generated_node_xmls": [],
                "merged_xml_file_paths": [],
                "current_step_description": "Reset to clean initial state (no stable checkpoint found)"
            }
            
            await sas_app.aupdate_state(config, initial_state_dict)
            
            return {
                "success": True, 
                "message": f"å·²é‡ç½®åˆ°å¹²å‡€çš„åˆå§‹çŠ¶æ€ (ä» {current_dialog_state})"
            }
        
        # è·å–ç›®æ ‡checkpointçš„å®Œæ•´çŠ¶æ€æ•°æ®
        target_config = target_checkpoint.config
        target_checkpoint_data = await sas_app.aget_state(target_config)
        
        if not target_checkpoint_data:
            raise Exception("æ— æ³•è·å–ç›®æ ‡checkpointçš„çŠ¶æ€æ•°æ®")
        
        target_state = dict(get_checkpoint_values(target_checkpoint_data))
        target_dialog_state = target_state.get('dialog_state')
        
        # å‡†å¤‡å›é€€çŠ¶æ€
        target_state['current_step_description'] = f"Reset to {target_dialog_state} checkpoint from stuck state"
        target_state['user_input'] = None
        target_state['is_error'] = False
        target_state['error_message'] = None
        
        # å¦‚æœå›é€€åˆ°å®¡æŸ¥çŠ¶æ€ï¼Œç¡®ä¿ç”¨æˆ·éœ€è¦é‡æ–°ç¡®è®¤
        if target_dialog_state == 'sas_awaiting_module_steps_review':
            target_state['module_steps_accepted'] = False
            target_state['completion_status'] = 'needs_clarification'
        elif target_dialog_state == 'sas_awaiting_task_list_review':
            target_state['task_list_accepted'] = False
            target_state['module_steps_accepted'] = False
            target_state['completion_status'] = 'needs_clarification'
        
        # ä½¿ç”¨LangGraph APIå®‰å…¨åœ°æ›´æ–°çŠ¶æ€
        await sas_app.aupdate_state(config, target_state)
        
        target_dialog_state = target_state.get('dialog_state')
        logger.info(f"Successfully reset stuck state for flow {flow_id} from {current_dialog_state} to {target_dialog_state}")
        
        return {
            "success": True, 
            "message": f"å·²ä»å¡ä½çŠ¶æ€é‡ç½®åˆ°: {target_dialog_state} (ä» {current_dialog_state})"
        }
            
    except Exception as e:
        logger.error(f"Failed to reset stuck state for flow {flow_id}: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"é‡ç½®å¡ä½çŠ¶æ€å¤±è´¥: {str(e)}")



@router.post("/{flow_id}/force-reset-state", response_model=schemas.SuccessResponse)
async def force_reset_state(
    flow_id: str,
    sas_app = Depends(get_sas_app),
    user: schemas.User = Depends(verify_flow_access_by_flow_id)
):
    """
    å¼ºåˆ¶é‡ç½®åˆ°æœ€æ—©çš„initial checkpointçŠ¶æ€ï¼ˆçœŸæ­£çš„checkpointå›é€€ï¼Œè€Œä¸æ˜¯æ‰‹åŠ¨æ„é€ çŠ¶æ€ï¼‰
    """
    try:
        config = {"configurable": {"thread_id": flow_id}}
        
        # è·å–å½“å‰çŠ¶æ€ä¿¡æ¯ï¼ˆç”¨äºæ—¥å¿—è®°å½•ï¼‰
        current_state_snapshot = await sas_app.aget_state(config)
        current_dialog_state = 'unknown'
        if current_state_snapshot:
            current_dialog_state = get_checkpoint_values(current_state_snapshot).get('dialog_state', 'unknown')
        
        logger.info(f"Force resetting flow {flow_id} from state: {current_dialog_state}")
        
        # è·å–å®Œæ•´çš„checkpointå†å²ï¼ˆæŒ‰æ—¶é—´å€’åºï¼‰
        checkpoint_history = []
        try:
            async for checkpoint_tuple in sas_app.aget_state_history(config):
                if checkpoint_tuple:  # ç®€åŒ–æ£€æŸ¥
                    checkpoint_history.append(checkpoint_tuple)
        except Exception as history_error:
            logger.warning(f"Error getting checkpoint history for flow {flow_id}: {history_error}")
            # å¦‚æœæ— æ³•è·å–å†å²ï¼Œç›´æ¥åˆ›å»ºå¹²å‡€çš„åˆå§‹çŠ¶æ€
            checkpoint_history = []
        
        # æŸ¥æ‰¾æœ€æ—©çš„initial checkpointï¼ˆä»å†å²åˆ—è¡¨çš„æœ«å°¾å¼€å§‹æŸ¥æ‰¾ï¼‰
        initial_checkpoint = None
        for checkpoint_tuple in reversed(checkpoint_history):
            try:
                # æ­£ç¡®è·å–checkpointçš„çŠ¶æ€æ•°æ® - éœ€è¦é€šè¿‡configé‡æ–°è·å–å®Œæ•´çŠ¶æ€
                checkpoint_config = checkpoint_tuple.config
                checkpoint_data = await sas_app.aget_state(checkpoint_config)
                if checkpoint_data:
                    checkpoint_values = get_checkpoint_values(checkpoint_data)
                    dialog_state = checkpoint_values.get('dialog_state')
                    
                    if dialog_state == 'initial':
                        initial_checkpoint = checkpoint_tuple
                        logger.info(f"Found initial checkpoint with state: {dialog_state}")
                        break
            except Exception as checkpoint_error:
                logger.warning(f"Error processing checkpoint for flow {flow_id}: {checkpoint_error}")
                continue
        
        if initial_checkpoint:
            # æ‰¾åˆ°äº†initial checkpointï¼Œå›é€€åˆ°è¯¥çŠ¶æ€
            try:
                # è·å–initial checkpointçš„å®Œæ•´çŠ¶æ€æ•°æ®
                target_config = initial_checkpoint.config
                target_checkpoint_data = await sas_app.aget_state(target_config)
                
                if not target_checkpoint_data:
                    raise Exception("æ— æ³•è·å–initial checkpointçš„çŠ¶æ€æ•°æ®")
                
                initial_state = dict(get_checkpoint_values(target_checkpoint_data))
                
                # å‡†å¤‡åˆå§‹çŠ¶æ€
                initial_state['current_step_description'] = 'Reset to initial checkpoint state'
                initial_state['user_input'] = None  # æ¸…ç†ç”¨æˆ·è¾“å…¥
                initial_state['is_error'] = False   # æ¸…é™¤é”™è¯¯çŠ¶æ€
                initial_state['error_message'] = None
                
                # ä½¿ç”¨LangGraph APIå®‰å…¨åœ°æ›´æ–°çŠ¶æ€
                await sas_app.aupdate_state(config, initial_state)
                
                logger.info(f"Successfully reset flow {flow_id} to initial checkpoint from {current_dialog_state}")
                return {
                    "success": True, 
                    "message": f"å·²é‡ç½®åˆ°initial checkpointçŠ¶æ€ (ä» {current_dialog_state})"
                }
            except Exception as rollback_error:
                logger.error(f"Failed to rollback to initial checkpoint for flow {flow_id}: {rollback_error}")
                # å¦‚æœå›é€€å¤±è´¥ï¼Œå°è¯•åˆ›å»ºå¹²å‡€çš„åˆå§‹çŠ¶æ€
                logger.warning(f"Rollback failed, creating fresh initial state for flow {flow_id}")
        
        # æ²¡æœ‰æ‰¾åˆ°initial checkpoint æˆ–è€… å›é€€å¤±è´¥ï¼Œåˆ›å»ºä¸€ä¸ªçœŸæ­£å¹²å‡€çš„åˆå§‹çŠ¶æ€
        logger.warning(f"No initial checkpoint found or rollback failed for flow {flow_id}, creating fresh initial state")
        
        # åˆ›å»ºå¹²å‡€çš„åˆå§‹çŠ¶æ€
        initial_state_dict = {
            "messages": [],
            "dialog_state": "initial",
            "config": {},
            "task_list_accepted": False,
            "module_steps_accepted": False,
            "is_error": False,
            "language": "zh",
            "relation_xml_content": "",
            "relation_xml_path": "",
            "revision_iteration": 0,
            "generated_node_xmls": [],
            "merged_xml_file_paths": [],
            "current_step_description": "Reset to clean initial state (no checkpoint found)",
            "user_input": None
        }
        
        await sas_app.aupdate_state(config, initial_state_dict)
        
        logger.info(f"Successfully reset flow {flow_id} to clean initial state from {current_dialog_state}")
        return {
            "success": True, 
            "message": f"å·²é‡ç½®åˆ°å¹²å‡€çš„åˆå§‹çŠ¶æ€ (ä» {current_dialog_state})"
        }
        
    except HTTPException:
        # é‡æ–°æŠ›å‡ºHTTPå¼‚å¸¸
        raise
    except Exception as e:
        logger.error(f"Failed to force reset to initial state for flow {flow_id}: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å¼ºåˆ¶é‡ç½®åˆ°åˆå§‹çŠ¶æ€å¤±è´¥: {str(e)}")

@router.post("/{flow_id}/rollback-to-previous", response_model=schemas.SuccessResponse)
async def rollback_to_previous_state(
    flow_id: str,
    sas_app = Depends(get_sas_app),
    user: schemas.User = Depends(verify_flow_access_by_flow_id)
):
    """
    å›é€€åˆ°ä¸Šä¸€ä¸ªç¨³å®šçš„checkpointçŠ¶æ€ï¼ˆçœŸæ­£çš„checkpointå›é€€ï¼Œä¸æ˜¯æ‰‹åŠ¨æ„é€ çŠ¶æ€ï¼‰
    """
    try:
        config = {"configurable": {"thread_id": flow_id}}
        
        # è·å–å½“å‰çŠ¶æ€ä¿¡æ¯ï¼ˆç”¨äºæ—¥å¿—è®°å½•ï¼‰
        current_state_snapshot = await sas_app.aget_state(config)
        if not current_state_snapshot:
            raise HTTPException(status_code=404, detail="æ— æ³•è·å–å½“å‰çŠ¶æ€ï¼Œæµç¨‹å¯èƒ½ä¸å­˜åœ¨æˆ–æœªåˆå§‹åŒ–")
        
        current_dialog_state = get_checkpoint_values(current_state_snapshot).get('dialog_state')
        logger.info(f"Current state for flow {flow_id}: {current_dialog_state}")
        
        # è·å–checkpointå†å²ï¼ˆæŒ‰æ—¶é—´å€’åºï¼‰
        checkpoint_history = []
        try:
            async for checkpoint_tuple in sas_app.aget_state_history(config):
                if checkpoint_tuple:  # ç®€åŒ–æ£€æŸ¥
                    checkpoint_history.append(checkpoint_tuple)
        except Exception as history_error:
            logger.error(f"è·å–checkpointå†å²å¤±è´¥: {history_error}")
            raise HTTPException(status_code=500, detail="è·å–å†å²çŠ¶æ€å¤±è´¥")
        
        if len(checkpoint_history) < 2:
            raise HTTPException(status_code=400, detail="No previous checkpoint available to roll back to.")
        
        # Define stable states for rollback targets
        stable_states = [
            'initial',
            'sas_awaiting_task_list_review',
            'sas_awaiting_module_steps_review'
        ]
        
        # Find the most recent stable checkpoint (skipping the current one)
        target_checkpoint = None
        target_checkpoint_index = None
        logger.info(f"Searching through {len(checkpoint_history)} checkpoints for stable state")
        
        for i in range(1, len(checkpoint_history)):
            checkpoint_tuple = checkpoint_history[i]
            
            # æ­£ç¡®è·å–checkpointçš„çŠ¶æ€æ•°æ®
            try:
                checkpoint_config = checkpoint_tuple.config
                checkpoint_data = await sas_app.aget_state(checkpoint_config)
                if checkpoint_data:
                    checkpoint_values = get_checkpoint_values(checkpoint_data)
                    dialog_state = checkpoint_values.get('dialog_state')
                    is_error = checkpoint_values.get('is_error', False)
                    
                    logger.debug(f"Checking checkpoint {i}: dialog_state={dialog_state}, is_error={is_error}")
                    
                    # å¯»æ‰¾ä¸€ä¸ªç¨³å®šä¸”æ— é”™è¯¯çš„checkpoint
                    if dialog_state in stable_states and not is_error:
                        target_checkpoint = checkpoint_tuple
                        target_checkpoint_index = i
                        logger.info(f"Found suitable rollback target: {dialog_state} at checkpoint {i}")
                        break
                else:
                    logger.warning(f"Could not get state data for checkpoint {i}")
            except Exception as e:
                logger.warning(f"Error checking checkpoint {i}: {e}")
                continue
        
        logger.info(f"Target checkpoint found: {target_checkpoint is not None}")
        
        if not target_checkpoint or target_checkpoint_index is None:
            # å¦‚æœæ‰¾ä¸åˆ°ä»»ä½•ç¨³å®šçŠ¶æ€ï¼Œè¿”å›é”™è¯¯
            logger.warning(f"No stable checkpoint found for flow {flow_id}")
            raise HTTPException(status_code=400, detail="æ²¡æœ‰æ‰¾åˆ°å¯ä»¥å›é€€çš„ç¨³å®šcheckpointçŠ¶æ€")
        
        # å®‰å…¨çš„å›æ»šï¼šä½¿ç”¨LangGraph APIæ¥åˆ›å»ºæ–°çš„checkpointï¼Œè€Œä¸æ˜¯åˆ é™¤æ—§çš„
        target_config = target_checkpoint.config
        
        logger.info(f"Rolling back to checkpoint at index {target_checkpoint_index}")
        
        try:
            # è·å–ç›®æ ‡checkpointçš„çŠ¶æ€æ•°æ®
            target_checkpoint_data = await sas_app.aget_state(target_config)
            if not target_checkpoint_data:
                raise Exception("æ— æ³•è·å–ç›®æ ‡checkpointçš„çŠ¶æ€æ•°æ®")
            
            target_state = get_checkpoint_values(target_checkpoint_data)
            target_dialog_state = target_state.get('dialog_state')
            
            # ä½¿ç”¨LangGraph APIå®‰å…¨åœ°æ›´æ–°çŠ¶æ€ï¼Œåˆ›å»ºæ–°çš„checkpoint
            # è¿™æ¯”ç›´æ¥åˆ é™¤æ•°æ®åº“è®°å½•æ›´å®‰å…¨ï¼Œä¿æŒäº†LangGraphçš„å†…éƒ¨ä¸€è‡´æ€§
            rollback_state = dict(target_state)  # å¤åˆ¶ç›®æ ‡çŠ¶æ€
            rollback_state['current_step_description'] = f"Rolled back to {target_dialog_state} checkpoint"
            rollback_state['user_input'] = None  # æ¸…é™¤ç”¨æˆ·è¾“å…¥
            rollback_state['is_error'] = False   # æ¸…é™¤é”™è¯¯çŠ¶æ€
            rollback_state['error_message'] = None
            
            # å¦‚æœå›é€€åˆ°å®¡æŸ¥çŠ¶æ€ï¼Œç¡®ä¿ç”¨æˆ·éœ€è¦é‡æ–°ç¡®è®¤
            if target_dialog_state == 'sas_awaiting_module_steps_review':
                rollback_state['module_steps_accepted'] = False
                rollback_state['completion_status'] = 'needs_clarification'
            elif target_dialog_state == 'sas_awaiting_task_list_review':
                rollback_state['task_list_accepted'] = False
                rollback_state['module_steps_accepted'] = False
                rollback_state['completion_status'] = 'needs_clarification'
            
            # ä½¿ç”¨aupdate_stateåˆ›å»ºæ–°çš„checkpoint
            config = {"configurable": {"thread_id": flow_id}}
            await sas_app.aupdate_state(config, rollback_state)
            
            logger.info(f"Successfully rolled back flow {flow_id} from {current_dialog_state} to {target_dialog_state}")
            
            return {
                "success": True, 
                "message": f"å·²å›é€€åˆ°checkpointçŠ¶æ€: {target_dialog_state} (ä» {current_dialog_state}ï¼Œé€šè¿‡åˆ›å»ºæ–°checkpointå®ç°)"
            }
            
        except Exception as rollback_error:
            logger.error(f"Failed to rollback to checkpoint: {rollback_error}")
            raise HTTPException(status_code=500, detail=f"å›æ»šåˆ°checkpointå¤±è´¥: {str(rollback_error)}")
        
    except HTTPException:
        # é‡æ–°æŠ›å‡ºHTTPå¼‚å¸¸
        raise
    except Exception as e:
        logger.error(f"Failed to rollback to previous checkpoint for flow {flow_id}: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"checkpointå›é€€å¤±è´¥: {str(e)}") 